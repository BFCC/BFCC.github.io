{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb6ylytVhWJg4vaN7jVWJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BFCC/BFCC.github.io/blob/main/Copy_of_Calabresi_N_grams_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_apsZ8jc-I-5",
        "outputId": "6f0b5c7d-de66-4aa9-8b10-3f15881bfd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from nltk.util import bigrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "r = requests.get(r'https://www.gutenberg.org/cache/epub/64317/pg64317.txt')\n",
        "great_gatsby = r.text\n",
        "\n",
        "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
        "    great_gatsby = great_gatsby.replace(char, \" \")\n",
        "\n",
        "print(great_gatsby[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvZAd4SJ_o47",
        "outputId": "e741ebe0-e7d6-44bf-edde-fb6d27e77b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Great Gatsby        This ebook is for the use of anyone anywhere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "great_gatsby = great_gatsby[983:]"
      ],
      "metadata": {
        "id": "1VFQ9lkO_xZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_clean_text(text: str):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "sample_tokens = sample_clean_text(text = great_gatsby)\n",
        "\n",
        "print(sample_tokens[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re--AdD0_3tx",
        "outputId": "17c96a0e-1132-4f17-9235-1e5aee7c68d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['then', 'wear', 'the', 'gold', 'hat', 'if', 'that', 'will', 'move', 'her', 'if', 'you', 'can', 'bounce', 'high', 'bounce', 'for', 'her', 'too', 'till', 'she', 'cry', 'lover', 'goldhatted', 'highbouncing', 'lover', 'i', 'must', 'have', 'you', 'thomas', 'parke', 'dinvilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'ive', 'been']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_bigrams = bigrams(sample_tokens)\n",
        "\n",
        "list(my_bigrams)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmy3JWAeAAqJ",
        "outputId": "c687c19b-2bc1-4fea-ba73-5bb30fbda0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('then', 'wear'),\n",
              " ('wear', 'the'),\n",
              " ('the', 'gold'),\n",
              " ('gold', 'hat'),\n",
              " ('hat', 'if'),\n",
              " ('if', 'that'),\n",
              " ('that', 'will'),\n",
              " ('will', 'move'),\n",
              " ('move', 'her'),\n",
              " ('her', 'if')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "text = great_gatsby"
      ],
      "metadata": {
        "id": "hgCH68WSAG1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
        "\n",
        "print(tokenized_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ijK6GAAPeo",
        "outputId": "bfa5fce4-6906-4cf1-f23f-317acf237454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oylzhEeHAcf0",
        "outputId": "156980d8-4c07-48ab-cfcf-6d9a4903eed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Then wear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "metadata": {
        "id": "92_2cp2lAm9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "\n",
        "lm = MLE(n)"
      ],
      "metadata": {
        "id": "lRxbexTHAsR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtnUCnkjAzoS",
        "outputId": "27bfd0b8-73f2-4cd7-ace0-1d8962418818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.fit(train_data, padded_sents)\n",
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg0GThxmA5AU",
        "outputId": "a36ec61b-dd68-4197-b318-23ff600d53d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6953"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(lm.vocab.lookup(tokenized_text[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkPMmqjBE4U",
        "outputId": "2c1bb309-3ac4-40c2-9a3f-143774bdab83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.vocab.lookup('then wear the gold hat iphone .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwucRNNbBIjq",
        "outputId": "6ed83971-bbc9-498c-fa20-258342f31089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', '<UNK>', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unknown!"
      ],
      "metadata": {
        "id": "dxioqGkZBSp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works!"
      ],
      "metadata": {
        "id": "1aXRmUf-BckT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.counts['daisy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQsYTJhRBRVa",
        "outputId": "8595c97c-ebfb-4155-bf47-7c5f5d49c8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score('daisy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nLj9r_UBe8S",
        "outputId": "2ed2a9d8-31f5-4765-b2ba-26bf9f47a528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026549057726065954"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.counts[['daisy']]['and'])\n",
        "lm.score('and', 'daisy'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMJ_GHheBtzS",
        "outputId": "b7fb2ab9-d9f9-4044-98da-f9e4c298e079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07650273224043716"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score(\"<UNK>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXvBOfjdB50T",
        "outputId": "cb624138-bae4-4723-fdf9-513a7402c6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not good: the model is too accurate.  We would have to add some randomness to make it function better."
      ],
      "metadata": {
        "id": "LKxFgzdiCDLm"
      }
    }
  ]
}