{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpWU3YI2nkuvYkmc8BKj93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BFCC/BFCC.github.io/blob/main/Calabresi_N_grams_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_apsZ8jc-I-5",
        "outputId": "6f0b5c7d-de66-4aa9-8b10-3f15881bfd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from nltk.util import bigrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "r = requests.get(r'https://www.gutenberg.org/cache/epub/64317/pg64317.txt')\n",
        "great_gatsby = r.text\n",
        "\n",
        "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
        "    great_gatsby = great_gatsby.replace(char, \" \")\n",
        "\n",
        "print(great_gatsby[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvZAd4SJ_o47",
        "outputId": "e741ebe0-e7d6-44bf-edde-fb6d27e77b88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Great Gatsby        This ebook is for the use of anyone anywhere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "great_gatsby = great_gatsby[983:]"
      ],
      "metadata": {
        "id": "1VFQ9lkO_xZv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_clean_text(text: str):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "sample_tokens = sample_clean_text(text = great_gatsby)\n",
        "\n",
        "print(sample_tokens[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re--AdD0_3tx",
        "outputId": "17c96a0e-1132-4f17-9235-1e5aee7c68d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['then', 'wear', 'the', 'gold', 'hat', 'if', 'that', 'will', 'move', 'her', 'if', 'you', 'can', 'bounce', 'high', 'bounce', 'for', 'her', 'too', 'till', 'she', 'cry', 'lover', 'goldhatted', 'highbouncing', 'lover', 'i', 'must', 'have', 'you', 'thomas', 'parke', 'dinvilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'ive', 'been']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_bigrams = bigrams(sample_tokens)\n",
        "\n",
        "list(my_bigrams)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmy3JWAeAAqJ",
        "outputId": "c687c19b-2bc1-4fea-ba73-5bb30fbda0df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('then', 'wear'),\n",
              " ('wear', 'the'),\n",
              " ('the', 'gold'),\n",
              " ('gold', 'hat'),\n",
              " ('hat', 'if'),\n",
              " ('if', 'that'),\n",
              " ('that', 'will'),\n",
              " ('will', 'move'),\n",
              " ('move', 'her'),\n",
              " ('her', 'if')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "text = great_gatsby"
      ],
      "metadata": {
        "id": "hgCH68WSAG1h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
        "\n",
        "print(tokenized_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ijK6GAAPeo",
        "outputId": "bfa5fce4-6906-4cf1-f23f-317acf237454"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oylzhEeHAcf0",
        "outputId": "156980d8-4c07-48ab-cfcf-6d9a4903eed3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Then wear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "metadata": {
        "id": "92_2cp2lAm9B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "\n",
        "lm = MLE(n)"
      ],
      "metadata": {
        "id": "lRxbexTHAsR2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtnUCnkjAzoS",
        "outputId": "27bfd0b8-73f2-4cd7-ace0-1d8962418818"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.fit(train_data, padded_sents)\n",
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg0GThxmA5AU",
        "outputId": "a36ec61b-dd68-4197-b318-23ff600d53d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6953"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(lm.vocab.lookup(tokenized_text[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkPMmqjBE4U",
        "outputId": "2c1bb309-3ac4-40c2-9a3f-143774bdab83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'if', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'till', 'she', 'cry', '“', 'lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'i', 'must', 'have', 'you', '!', '”', 'thomas', 'parke', 'd', '’', 'invilliers', 'i', 'in', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'i', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.vocab.lookup('then wear the gold hat iphone .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwucRNNbBIjq",
        "outputId": "6ed83971-bbc9-498c-fa20-258342f31089"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('then', 'wear', 'the', 'gold', 'hat', '<UNK>', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unknown!"
      ],
      "metadata": {
        "id": "dxioqGkZBSp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works!"
      ],
      "metadata": {
        "id": "1aXRmUf-BckT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.counts['daisy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQsYTJhRBRVa",
        "outputId": "8595c97c-ebfb-4155-bf47-7c5f5d49c8fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score('daisy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nLj9r_UBe8S",
        "outputId": "2ed2a9d8-31f5-4765-b2ba-26bf9f47a528"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026549057726065954"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.counts[['daisy']]['and'])\n",
        "lm.score('and', 'daisy'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMJ_GHheBtzS",
        "outputId": "b7fb2ab9-d9f9-4044-98da-f9e4c298e079"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07650273224043716"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.score(\"<UNK>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXvBOfjdB50T",
        "outputId": "cb624138-bae4-4723-fdf9-513a7402c6d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not good: the model is too accurate.  We would have to add some randomness to make it function better."
      ],
      "metadata": {
        "id": "LKxFgzdiCDLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.generate(20, text_seed= 'daisy', random_seed=42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wenNkmtPEPqK",
        "outputId": "ddfd2b49-9844-4966-dd36-accc90f0a41d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['other', ',', 'but', 'he', 'turned', 'to', 'their', 'cars', 'blocking', 'the', 'dull', 'light', ',', 'and', 'separated', 'only', 'building', 'in', 'the', 'adventitious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "metadata": {
        "id": "7vQtDyTYEVoa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 20, text_seed='daisy', random_seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2i-KrxJkEeZW",
        "outputId": "68284b9c-d210-4450-cae5-32a9a52215f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other, but he turned to their cars blocking the dull light, and separated only building in the adventitious'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(lm.generate(20, text_seed= 'golden', random_seed=42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHzLWZg2Exib",
        "outputId": "8c57cad1-01b5-45ea-fadb-b3688df25ebd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['forty', '.', '</s>', 'and', 'the', 'rain', 'with', 'a', 'little', ',', 'as', 'it', ',', 'and', 'separated', 'only', 'building', 'in', 'the', 'adventitious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 20, text_seed='golden', random_seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z4mb5d_IFzr3",
        "outputId": "5d7b6a72-fc46-4a53-f99a-18bc0aa9e862"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'forty.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm.generate(20, text_seed= 'tennis', random_seed=42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8gH6EOSF63y",
        "outputId": "ce288fe1-0335-4629-ef90-01f4dc7201c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['names', ')', '596-1887', '.', '</s>', 'ridges', 'and', 'aware', 'of', 'a', 'drugstore', 'nowadays.', '”', 'he', 'spoke', 'rapidly', '.', '</s>', 'thing', ',']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 20, text_seed='tennis', random_seed = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "09rZcCWeGL9U",
        "outputId": "257bf2d2-50c5-488d-e3b4-5b01cb12c254"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'names) 596-1887.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}